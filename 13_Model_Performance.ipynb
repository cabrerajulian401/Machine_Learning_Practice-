{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18799057-4849-41f6-95ea-bb4ce9f5128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202be12f-f242-4fb8-8a4c-427c12cc2702",
   "metadata": {},
   "source": [
    "# Processing Pipeline I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602813d-e163-4dd5-97ea-86f720bc928d",
   "metadata": {},
   "source": [
    "## I.1. Loading the Breast Cancer Wisconsin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b67c2a-9c2c-4688-9acb-76444497fcf9",
   "metadata": {},
   "source": [
    "We are going to use train a logistic regression model on this dataset to predict whether a tumor is malignant (M) or benign (B). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41070146-8772-4141-980f-f32aff33918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fetch dataset \n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "# breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "\n",
    "# # data (as pandas dataframes) \n",
    "# features = breast_cancer_wisconsin_diagnostic.data.features \n",
    "# labels = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# df = pd.concat([features, labels], axis=1)\n",
    "# df.to_csv('wbdc.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('wbdc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7960a81-6537-476d-873a-d4549ea5855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  texture3  \\\n",
       "0      0.3001          0.14710     0.2419             0.07871  ...     17.33   \n",
       "1      0.0869          0.07017     0.1812             0.05667  ...     23.41   \n",
       "2      0.1974          0.12790     0.2069             0.05999  ...     25.53   \n",
       "3      0.2414          0.10520     0.2597             0.09744  ...     26.50   \n",
       "4      0.1980          0.10430     0.1809             0.05883  ...     16.67   \n",
       "\n",
       "   perimeter3   area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "0      184.60  2019.0       0.1622        0.6656      0.7119           0.2654   \n",
       "1      158.80  1956.0       0.1238        0.1866      0.2416           0.1860   \n",
       "2      152.50  1709.0       0.1444        0.4245      0.4504           0.2430   \n",
       "3       98.87   567.7       0.2098        0.8663      0.6869           0.2575   \n",
       "4      152.20  1575.0       0.1374        0.2050      0.4000           0.1625   \n",
       "\n",
       "   symmetry3  fractal_dimension3  Diagnosis  \n",
       "0     0.4601             0.11890          M  \n",
       "1     0.2750             0.08902          M  \n",
       "2     0.3613             0.08758          M  \n",
       "3     0.6638             0.17300          M  \n",
       "4     0.2364             0.07678          M  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cfaf09-5e69-4fda-a8e1-db5181612702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31004c97-73e5-4a01-a5f3-e71ec9460365",
   "metadata": {},
   "source": [
    "## I.2. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18d2f08-cd2d-4689-adcf-680c381e8833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius1               0\n",
       "texture1              0\n",
       "perimeter1            0\n",
       "area1                 0\n",
       "smoothness1           0\n",
       "compactness1          0\n",
       "concavity1            0\n",
       "concave_points1       0\n",
       "symmetry1             0\n",
       "fractal_dimension1    0\n",
       "radius2               0\n",
       "texture2              0\n",
       "perimeter2            0\n",
       "area2                 0\n",
       "smoothness2           0\n",
       "compactness2          0\n",
       "concavity2            0\n",
       "concave_points2       0\n",
       "symmetry2             0\n",
       "fractal_dimension2    0\n",
       "radius3               0\n",
       "texture3              0\n",
       "perimeter3            0\n",
       "area3                 0\n",
       "smoothness3           0\n",
       "compactness3          0\n",
       "concavity3            0\n",
       "concave_points3       0\n",
       "symmetry3             0\n",
       "fractal_dimension3    0\n",
       "Diagnosis             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a4457-176f-48b8-af2d-e8fb6c966c83",
   "metadata": {},
   "source": [
    "No missing data in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197ae7a-84e5-4bba-9497-629205ba28bf",
   "metadata": {},
   "source": [
    "## I.3 Get Predictor Variables (X) and Target Variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36838a52-9736-40f8-8741-72d6601a0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   radius1             569 non-null    float64\n",
      " 1   texture1            569 non-null    float64\n",
      " 2   perimeter1          569 non-null    float64\n",
      " 3   area1               569 non-null    float64\n",
      " 4   smoothness1         569 non-null    float64\n",
      " 5   compactness1        569 non-null    float64\n",
      " 6   concavity1          569 non-null    float64\n",
      " 7   concave_points1     569 non-null    float64\n",
      " 8   symmetry1           569 non-null    float64\n",
      " 9   fractal_dimension1  569 non-null    float64\n",
      " 10  radius2             569 non-null    float64\n",
      " 11  texture2            569 non-null    float64\n",
      " 12  perimeter2          569 non-null    float64\n",
      " 13  area2               569 non-null    float64\n",
      " 14  smoothness2         569 non-null    float64\n",
      " 15  compactness2        569 non-null    float64\n",
      " 16  concavity2          569 non-null    float64\n",
      " 17  concave_points2     569 non-null    float64\n",
      " 18  symmetry2           569 non-null    float64\n",
      " 19  fractal_dimension2  569 non-null    float64\n",
      " 20  radius3             569 non-null    float64\n",
      " 21  texture3            569 non-null    float64\n",
      " 22  perimeter3          569 non-null    float64\n",
      " 23  area3               569 non-null    float64\n",
      " 24  smoothness3         569 non-null    float64\n",
      " 25  compactness3        569 non-null    float64\n",
      " 26  concavity3          569 non-null    float64\n",
      " 27  concave_points3     569 non-null    float64\n",
      " 28  symmetry3           569 non-null    float64\n",
      " 29  fractal_dimension3  569 non-null    float64\n",
      " 30  Diagnosis           569 non-null    object \n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f0efa4-0c6f-44e2-b5c4-7e0dfa11efd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a <class 'numpy.ndarray'> of size (569, 30)\n"
     ]
    }
   ],
   "source": [
    "## get predictor variables (features) X\n",
    "X = df.iloc[:, :-1].values\n",
    "print(f'X is a {type(X)} of size {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508db93c-9adb-477b-b4c6-8a3572451062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y is a <class 'numpy.ndarray'> of size (569,)\n"
     ]
    }
   ],
   "source": [
    "## get target variable (class label) Y\n",
    "Y = df.iloc[:, -1].values\n",
    "print(f'Y is a {type(Y)} of size {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a93860-f31d-47fe-ab81-b19846d52419",
   "metadata": {},
   "source": [
    "## I.4. Encoding categorical columns into numerical columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfecf51-72f9-49ee-a7d1-8bdf3e5a01e1",
   "metadata": {},
   "source": [
    "All columns in ```X``` are numerical columns. Hence, no need for column encoding for `X`. However since we are going to train a logistic regression model then we need to encode the categorical label in `Y` into numerical label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f772f7-dd54-4018-adf3-22574520039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa21a6c-0db4-45f7-a415-e10115a9657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3edcf-7d67-4a29-b36c-5d5213f2bb78",
   "metadata": {},
   "source": [
    "We can double check the mapping as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6df8f1e-9c3c-4d2d-974e-10df6e69f46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['M', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f596684-41bb-42db-8f88-f1dc97817719",
   "metadata": {},
   "source": [
    "In this case the malignant (M) label is transformed to class 1 while the benign (B) label is transformed to class 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2384d39c-c006-44fd-aae4-b71f1e3bf1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c2804b7-70a2-4e1f-949d-530849435e4a",
   "metadata": {},
   "source": [
    "# Training classifier and assessing its performance using k-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7da5983-f0de-45ae-aac6-4700d6ed055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95604396 0.98901099 0.97802198 0.97802198 0.98901099]\n",
      "Mean CV Accuracy: 0.9780\n",
      "Standard Deviation of CV Scores: 0.0120\n",
      "Test Set Accuracy (Generalization Performance): 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with StandardScaler, PCA, and LogisticRegression\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         PCA(),\n",
    "                         LogisticRegression())\n",
    "\n",
    "# Define K-Fold Cross-Validation\n",
    "k = 5  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Cross-Validation on Training Data\n",
    "cv_scores = cross_val_score(pipeline, X_train, Y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Train the model on the full training data\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model on the separate test set\n",
    "Y_test_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation of CV Scores: {cv_scores.std():.4f}\")\n",
    "print(f\"Test Set Accuracy (Generalization Performance): {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
