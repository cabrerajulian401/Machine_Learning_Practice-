{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95b2d2b0-4c34-4d00-aea7-118fb927ce27",
   "metadata": {},
   "source": [
    "In this exercise, you will practice to build Logistic Regression models for multiclass classification using One-vs-the-rest (OvR) multiclass strategy while applying regularization.\n",
    "Answer Q0-Q13 in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70816d-c338-4f9f-bb18-d1a53338957e",
   "metadata": {},
   "source": [
    "## Q0 : Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516da722-3fe0-42cb-8e55-35624a32b012",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "https://archive.ics.uci.edu/dataset/109/wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a42646b-aff0-475b-bbab-9126f8440d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0      14.23       1.71  2.43               15.6        127           2.80   \n",
       "1      13.20       1.78  2.14               11.2        100           2.65   \n",
       "2      13.16       2.36  2.67               18.6        101           2.80   \n",
       "3      14.37       1.95  2.50               16.8        113           3.85   \n",
       "4      13.24       2.59  2.87               21.0        118           2.80   \n",
       "..       ...        ...   ...                ...        ...            ...   \n",
       "173    13.71       5.65  2.45               20.5         95           1.68   \n",
       "174    13.40       3.91  2.48               23.0        102           1.80   \n",
       "175    13.27       4.28  2.26               20.0        120           1.59   \n",
       "176    13.17       2.59  2.37               20.0        120           1.65   \n",
       "177    14.13       4.10  2.74               24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     0D280_0D315_of_diluted_wines  Proline  class  \n",
       "0                            3.92     1065      1  \n",
       "1                            3.40     1050      1  \n",
       "2                            3.17     1185      1  \n",
       "3                            3.45     1480      1  \n",
       "4                            2.93      735      1  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74      740      3  \n",
       "174                          1.56      750      3  \n",
       "175                          1.56      835      3  \n",
       "176                          1.62      840      3  \n",
       "177                          1.60      560      3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('wine.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e268f8b4-aefe-4e4d-95b4-364eedc1c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding out the unique labels in the dataset\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8da13-1a2e-491f-bf0b-4149982c0ce9",
   "metadata": {},
   "source": [
    "Q1: Show the statistics of the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47a9c1-d60c-45e6-9d6c-e1fdfa936f10",
   "metadata": {},
   "source": [
    "Q2: Use heatmap to show the correlation between the numerical features. Are there any pairs of highly correlated numerical features (i.e having correlation values greater than 0.7 or less than -0.7)? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1816095-d6fc-47f1-8fb7-dc85fa4708fd",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc538e76-7f0a-4fa5-ba09-9f3968e93685",
   "metadata": {},
   "source": [
    "Q3: Is there any missing values in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06d446-fbfd-464f-8ea9-79b7ad52201f",
   "metadata": {},
   "source": [
    "Q4: Are there any categorical variables that need encoding? If so, proceed with encoding them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a167aff-7af5-4bef-bf9d-ddb648c08373",
   "metadata": {},
   "source": [
    "Q5: Split the dataset into 80% training set and 20% testing set. Set the random_state = 13. Print the size of the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fea79c-20b8-4f28-89c7-c22858020d01",
   "metadata": {},
   "source": [
    "Q6: Do the input features need to be standardized? If so, explain why and proceed to standardize the training and testing set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb4d1b3b-fc83-4024-978f-3f4fe1217145",
   "metadata": {},
   "source": [
    "## One-vs-the-rest (OvR) multiclass strategy using Logistic Regression without Reqularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b531ea-93dc-419d-a1e5-6b9c8a92a17e",
   "metadata": {},
   "source": [
    "Q7: Use OneVsRestClassifier to train logistic regression models. Make sure no regularization by passing the estimator for ```OneVsRestClassifier``` as ```LogisticRegression```(penalty=None). \n",
    "In your opinion, how many total models will be trained using this strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37200c24-6610-47df-a4a2-ee77d050f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb5a5a-7446-4a0f-bec4-4866cfc860a9",
   "metadata": {},
   "source": [
    "Q8: Show the list of train the models (estimators). You can use the ```estimators_``` attribute from the instance of OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568996b9-8413-4b41-9d0b-22cf347b5830",
   "metadata": {},
   "source": [
    "Q9: Show the prediction probability of the first instance in the testing set and explain what the values represent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea04fe-2f7f-4fd8-af7c-90df2bc57323",
   "metadata": {},
   "source": [
    "Q10: Show the predicted label of the first five instances in the testing set and compare them with their actual labels. Are there any missclassified instances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa3c74-bcd2-4462-9a5e-55f49032cfe9",
   "metadata": {},
   "source": [
    "Q11: Show the prediction accuracy of the models on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbc07d-b887-4c34-9bc0-8a8dc41ab460",
   "metadata": {},
   "source": [
    "## One-vs-the-rest (OvR) multiclass strategy using Logistic Regression with Reqularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13600616-261e-4fe5-9005-9ae17c41d3c8",
   "metadata": {},
   "source": [
    "Q12: Use OneVsRestClassifier to train logistic regression models with L2 regularization . Set the regularization parameter C=1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e566e-ce12-4de1-9eb2-21f916a79b11",
   "metadata": {},
   "source": [
    "Q13: Show the prediction accuracy on the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
